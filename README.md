# Hand Gesture Recognition System for Sign Language (HGRSLTV)

A deep learning-powered web application that helps deaf and mute individuals communicate by translating hand gestures into text and speech.

## ğŸ” Overview

Many people with speech and hearing disabilities rely on sign language to communicate. Unfortunately, not everyone understands sign language. This project bridges that communication gap using computer vision and deep learning.

The system captures hand gestures using a webcam and converts them into corresponding text and speech using image recognition and audio synthesis.

Published in: *International Journal for Modern Trends in Science and Technology (IJMTST), Vol. 8(06), 2022*

ğŸ“„ [Read the paper](https://doi.org/10.46501/IJMTST0806016)

## ğŸ¯ Features

- Real-time hand gesture recognition
- Conversion of gestures to text
- Voice output for recognized gestures
- Intelligent suggestions to form complete sentences
- Web-based interface for ease of use

## ğŸ› ï¸ Tech Stack

- Python
- OpenCV
- TensorFlow / Keras
- Flask / Django (if web backend used)
- HTML/CSS/JavaScript
- Text-to-Speech (TTS) APIs

## ğŸ§  Model

The gesture recognition model is trained on a custom dataset of hand signs. Pre-processing steps include resizing, normalization, and augmentation for better generalization.
